{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Spectrogrammes NightScan\n",
    "\n",
    "Ce notebook permet d'analyser et visualiser les spectrogrammes générés avec différentes configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Importer nos modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from spectrogram_config import SpectrogramConfig, get_config_for_animal, ANIMAL_FREQ_RANGES\n",
    "from audio_augmentation import AudioAugmentation, PreprocessingPipeline\n",
    "from audio_dataset import AudioSpectrogramDataset\n",
    "\n",
    "# Configuration du style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparaison des configurations par type d'animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les paramètres pour chaque type d'animal\n",
    "config_comparison = []\n",
    "\n",
    "for animal_type in ANIMAL_FREQ_RANGES.keys():\n",
    "    config = get_config_for_animal(animal_type)\n",
    "    config_comparison.append({\n",
    "        'Type': animal_type,\n",
    "        'Sample Rate': config.sample_rate,\n",
    "        'n_mels': config.n_mels,\n",
    "        'fmin': config.fmin,\n",
    "        'fmax': config.fmax,\n",
    "        'n_fft': config.n_fft,\n",
    "        'hop_length': config.hop_length\n",
    "    })\n",
    "\n",
    "df_config = pd.DataFrame(config_comparison)\n",
    "display(df_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation des plages de fréquences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les plages de fréquences pour chaque animal\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "y_pos = np.arange(len(ANIMAL_FREQ_RANGES))\n",
    "animals = list(ANIMAL_FREQ_RANGES.keys())\n",
    "\n",
    "for i, animal in enumerate(animals):\n",
    "    config = get_config_for_animal(animal)\n",
    "    ax.barh(i, config.fmax - config.fmin, left=config.fmin, height=0.6,\n",
    "            label=f\"{animal} ({config.fmin}-{config.fmax} Hz)\")\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(animals)\n",
    "ax.set_xlabel('Fréquence (Hz)')\n",
    "ax.set_title('Plages de fréquences par type d\\'animal')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Génération et comparaison de spectrogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_signal(duration=3, sample_rate=22050, freq_components=None):\n",
    "    \"\"\"Génère un signal de test avec plusieurs composantes fréquentielles.\"\"\"\n",
    "    t = torch.linspace(0, duration, int(sample_rate * duration))\n",
    "    \n",
    "    if freq_components is None:\n",
    "        freq_components = [(1000, 0.5), (2000, 0.3), (4000, 0.2)]\n",
    "    \n",
    "    signal = torch.zeros_like(t)\n",
    "    for freq, amp in freq_components:\n",
    "        signal += amp * torch.sin(2 * np.pi * freq * t)\n",
    "    \n",
    "    # Ajouter un peu de bruit\n",
    "    signal += 0.05 * torch.randn_like(signal)\n",
    "    \n",
    "    return signal.unsqueeze(0)  # Ajouter dimension channel\n",
    "\n",
    "def plot_spectrogram(spec, title, ax, sample_rate=22050, hop_length=512):\n",
    "    \"\"\"Affiche un spectrogramme.\"\"\"\n",
    "    img = ax.imshow(spec, aspect='auto', origin='lower', cmap='viridis')\n",
    "    \n",
    "    # Configurer les axes\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Temps (s)')\n",
    "    ax.set_ylabel('Fréquence (mel)')\n",
    "    \n",
    "    # Ajuster les labels de temps\n",
    "    time_frames = spec.shape[1]\n",
    "    time_seconds = time_frames * hop_length / sample_rate\n",
    "    ax.set_xlim(0, time_frames)\n",
    "    \n",
    "    # Créer des ticks de temps\n",
    "    n_ticks = 5\n",
    "    tick_locs = np.linspace(0, time_frames, n_ticks)\n",
    "    tick_labels = np.linspace(0, time_seconds, n_ticks)\n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_xticklabels([f'{t:.1f}' for t in tick_labels])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les spectrogrammes pour différentes configurations\n",
    "test_signal = generate_test_signal(duration=3)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, animal_type in enumerate(['general', 'bird_song', 'owl', 'bat', 'insect', 'amphibian']):\n",
    "    config = get_config_for_animal(animal_type)\n",
    "    \n",
    "    # Adapter le signal au sample rate de la config\n",
    "    if config.sample_rate != 22050:\n",
    "        resampler = T.Resample(22050, config.sample_rate)\n",
    "        signal = resampler(test_signal)\n",
    "    else:\n",
    "        signal = test_signal\n",
    "    \n",
    "    # Créer le spectrogramme\n",
    "    mel_transform = T.MelSpectrogram(\n",
    "        sample_rate=config.sample_rate,\n",
    "        n_mels=config.n_mels,\n",
    "        n_fft=config.n_fft,\n",
    "        hop_length=config.hop_length,\n",
    "        f_min=config.fmin,\n",
    "        f_max=config.fmax\n",
    "    )\n",
    "    \n",
    "    mel_spec = mel_transform(signal)\n",
    "    mel_spec_db = T.AmplitudeToDB(top_db=config.top_db)(mel_spec)\n",
    "    \n",
    "    plot_spectrogram(\n",
    "        mel_spec_db.squeeze().numpy(),\n",
    "        f'{animal_type}\\n(sr={config.sample_rate}, fmin={config.fmin}, fmax={config.fmax})',\n",
    "        axes[i],\n",
    "        config.sample_rate,\n",
    "        config.hop_length\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse de l'augmentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un signal de test\n",
    "original_signal = generate_test_signal(duration=3)\n",
    "augmenter = AudioAugmentation()\n",
    "\n",
    "# Appliquer différentes augmentations\n",
    "augmentations = {\n",
    "    'Original': original_signal,\n",
    "    'Avec bruit': augmenter.add_noise(original_signal, noise_level=0.1),\n",
    "    'Décalage temporel': augmenter.time_shift(original_signal),\n",
    "    'Changement vitesse': augmenter.change_speed(original_signal, speed_factor=1.1),\n",
    "    'Pitch shift': augmenter.pitch_shift(original_signal, n_steps=2)\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "config = SpectrogramConfig()  # Config par défaut\n",
    "mel_transform = T.MelSpectrogram(\n",
    "    sample_rate=config.sample_rate,\n",
    "    n_mels=config.n_mels,\n",
    "    n_fft=config.n_fft,\n",
    "    hop_length=config.hop_length\n",
    ")\n",
    "\n",
    "for i, (name, signal) in enumerate(augmentations.items()):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "        \n",
    "    mel_spec = mel_transform(signal)\n",
    "    mel_spec_db = T.AmplitudeToDB(top_db=80)(mel_spec)\n",
    "    \n",
    "    plot_spectrogram(\n",
    "        mel_spec_db.squeeze().numpy(),\n",
    "        name,\n",
    "        axes[i],\n",
    "        config.sample_rate,\n",
    "        config.hop_length\n",
    "    )\n",
    "\n",
    "# Cacher le dernier subplot vide\n",
    "if len(augmentations) < len(axes):\n",
    "    axes[-1].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse SpecAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Démonstration de SpecAugment\n",
    "original_spec = mel_transform(original_signal)\n",
    "original_spec_db = T.AmplitudeToDB(top_db=80)(original_spec)\n",
    "\n",
    "# Appliquer SpecAugment plusieurs fois\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_spectrogram(\n",
    "    original_spec_db.squeeze().numpy(),\n",
    "    'Spectrogramme original',\n",
    "    axes[0],\n",
    "    config.sample_rate,\n",
    "    config.hop_length\n",
    ")\n",
    "\n",
    "for i in range(1, 4):\n",
    "    augmented_spec = augmenter.spec_augment(original_spec_db.clone())\n",
    "    plot_spectrogram(\n",
    "        augmented_spec.squeeze().numpy(),\n",
    "        f'SpecAugment #{i}',\n",
    "        axes[i],\n",
    "        config.sample_rate,\n",
    "        config.hop_length\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyse des vrais données (si disponibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et analyser de vraies données si disponibles\n",
    "csv_path = Path('../data/processed/csv/train.csv')\n",
    "audio_dir = Path('../audio_data')\n",
    "\n",
    "if csv_path.exists() and audio_dir.exists():\n",
    "    # Charger le dataset\n",
    "    dataset = AudioSpectrogramDataset(\n",
    "        csv_file=csv_path,\n",
    "        audio_dir=audio_dir,\n",
    "        animal_type='general',\n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    if len(dataset) > 0:\n",
    "        print(f\"Dataset chargé: {len(dataset)} échantillons\")\n",
    "        print(f\"Classes: {dataset.class_names}\")\n",
    "        \n",
    "        # Visualiser quelques échantillons par classe\n",
    "        n_samples_per_class = 2\n",
    "        n_classes = len(dataset.class_names)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_classes, n_samples_per_class, \n",
    "                                figsize=(n_samples_per_class * 5, n_classes * 3))\n",
    "        \n",
    "        if n_classes == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        # Grouper par classe\n",
    "        samples_by_class = {class_name: [] for class_name in dataset.class_names}\n",
    "        \n",
    "        for i in range(len(dataset)):\n",
    "            spec, label_idx = dataset[i]\n",
    "            class_name = dataset.class_names[label_idx]\n",
    "            if len(samples_by_class[class_name]) < n_samples_per_class:\n",
    "                samples_by_class[class_name].append((spec, i))\n",
    "        \n",
    "        # Afficher\n",
    "        for class_idx, class_name in enumerate(dataset.class_names):\n",
    "            for sample_idx, (spec, dataset_idx) in enumerate(samples_by_class[class_name][:n_samples_per_class]):\n",
    "                ax = axes[class_idx, sample_idx] if n_classes > 1 else axes[sample_idx]\n",
    "                \n",
    "                # Prendre le premier canal si RGB\n",
    "                if spec.shape[0] == 3:\n",
    "                    spec_to_plot = spec[0].numpy()\n",
    "                else:\n",
    "                    spec_to_plot = spec.numpy()\n",
    "                \n",
    "                img = ax.imshow(spec_to_plot, aspect='auto', origin='lower', cmap='viridis')\n",
    "                ax.set_title(f'{class_name} - Sample {dataset_idx}')\n",
    "                ax.set_xlabel('Temps')\n",
    "                ax.set_ylabel('Fréquence (mel)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistiques sur les spectrogrammes\n",
    "        print(\"\\nStatistiques des spectrogrammes:\")\n",
    "        specs = []\n",
    "        for i in range(min(100, len(dataset))):\n",
    "            spec, _ = dataset[i]\n",
    "            specs.append(spec.numpy())\n",
    "        \n",
    "        specs = np.array(specs)\n",
    "        print(f\"Forme: {specs.shape}\")\n",
    "        print(f\"Min: {specs.min():.2f}, Max: {specs.max():.2f}\")\n",
    "        print(f\"Moyenne: {specs.mean():.2f}, Écart-type: {specs.std():.2f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Pas de données réelles trouvées. Exécutez d'abord prepare_audio_data.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommandations basées sur l'analyse\n",
    "\n",
    "### Paramètres optimaux détectés:\n",
    "\n",
    "1. **Général (défaut)**:\n",
    "   - Sample rate: 22050 Hz\n",
    "   - n_mels: 128\n",
    "   - fmin: 50 Hz, fmax: 11000 Hz\n",
    "   - Bon compromis pour la plupart des animaux\n",
    "\n",
    "2. **Chauves-souris**:\n",
    "   - Sample rate: 192000 Hz (pour capturer les ultrasons)\n",
    "   - n_mels: 256 (plus de résolution)\n",
    "   - fmin: 15000 Hz, fmax: 100000 Hz\n",
    "\n",
    "3. **Chouettes**:\n",
    "   - Sample rate: 16000 Hz (suffisant pour basses fréquences)\n",
    "   - fmin: 200 Hz, fmax: 4000 Hz\n",
    "\n",
    "### Augmentation des données:\n",
    "\n",
    "- **SpecAugment** très efficace pour la généralisation\n",
    "- **Bruit gaussien** simule les conditions réelles\n",
    "- **Décalage temporel** pour la robustesse\n",
    "- **Changement de vitesse** simule différentes distances\n",
    "\n",
    "### Prétraitement recommandé:\n",
    "\n",
    "1. Filtre passe-haut (50 Hz) pour éliminer le bruit\n",
    "2. Normalisation par spectrogramme\n",
    "3. Conversion en RGB pour compatibilité avec les modèles pré-entraînés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder un rapport\n",
    "report = {\n",
    "    'date': pd.Timestamp.now().isoformat(),\n",
    "    'configurations': df_config.to_dict(),\n",
    "    'recommendations': {\n",
    "        'general': 'Utiliser la configuration par défaut pour commencer',\n",
    "        'bat_detection': 'Nécessite matériel spécialisé (microphone ultrasonique)',\n",
    "        'augmentation': 'Activer pour améliorer la généralisation',\n",
    "        'preprocessing': 'Toujours filtrer < 50 Hz'\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('spectrogram_analysis_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"Rapport sauvegardé dans spectrogram_analysis_report.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}