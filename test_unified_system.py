#!/usr/bin/env python3
"""
Test du syst√®me unifi√© avec les mod√®les EfficientNet r√©els
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
import json
import logging
from datetime import datetime

# Add parent directory to path
sys.path.append(str(Path(__file__).parent))

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_model_loading():
    """Test le chargement des mod√®les depuis le registre."""
    print("üîç Test de chargement des mod√®les depuis le registre")
    print("=" * 50)
    
    try:
        from model_registry import get_model_registry
        registry = get_model_registry()
        
        # V√©rifier les mod√®les dans le registre
        stats = registry.get_registry_stats()
        print(f"‚úÖ Registre charg√©: {stats['total_models']} mod√®les")
        print(f"   Audio: {stats['audio_models']}, Photo: {stats['photo_models']}")
        print(f"   L√©gers: {stats['light_models']}, Lourds: {stats['heavy_models']}")
        
        # Tester le chargement des mod√®les lourds
        audio_heavy = registry.get_model("audio_heavy_v1")
        photo_heavy = registry.get_model("photo_heavy_v1")
        
        if audio_heavy and Path(audio_heavy.file_path).exists():
            print(f"‚úÖ Mod√®le audio lourd trouv√©: {audio_heavy.file_path}")
        else:
            print("‚ùå Mod√®le audio lourd introuvable")
        
        if photo_heavy and Path(photo_heavy.file_path).exists():
            print(f"‚úÖ Mod√®le photo lourd trouv√©: {photo_heavy.file_path}")
        else:
            print("‚ùå Mod√®le photo lourd introuvable")
        
        # Tester le chargement des mod√®les l√©gers
        audio_light = registry.get_model("audio_light_v1")
        photo_light = registry.get_model("photo_light_v1")
        
        if audio_light and Path(audio_light.file_path).exists():
            print(f"‚úÖ Mod√®le audio l√©ger trouv√©: {audio_light.file_path}")
        else:
            print("‚ùå Mod√®le audio l√©ger introuvable")
        
        if photo_light and Path(photo_light.file_path).exists():
            print(f"‚úÖ Mod√®le photo l√©ger trouv√©: {photo_light.file_path}")
        else:
            print("‚ùå Mod√®le photo l√©ger introuvable")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur test registre: {e}")
        return False

def test_model_inference():
    """Test l'inf√©rence des mod√®les."""
    print("\\nüß™ Test d'inf√©rence des mod√®les")
    print("=" * 50)
    
    try:
        # Test mod√®le audio lourd
        print("üì¶ Chargement du mod√®le audio lourd...")
        checkpoint = torch.load('audio_training_efficientnet/models/best_model.pth', map_location='cpu')
        
        from audio_training_efficientnet.models.efficientnet_config import create_audio_model
        audio_model = create_audio_model(
            num_classes=6,
            model_name='efficientnet-b1',
            pretrained=False
        )
        audio_model.load_state_dict(checkpoint['model_state_dict'])
        audio_model.eval()
        
        # Test avec spectrogramme synth√©tique
        with torch.no_grad():
            audio_input = torch.randn(1, 3, 128, 128)
            audio_output = audio_model(audio_input)
            audio_probs = torch.softmax(audio_output, dim=1)
            audio_pred = torch.argmax(audio_probs, dim=1)
            
        class_names_audio = ['bird_song', 'mammal_call', 'insect_sound', 'amphibian_call', 'environmental_sound', 'unknown_species']
        print(f"‚úÖ Audio heavy - Pr√©diction: {class_names_audio[audio_pred.item()]} (confiance: {audio_probs.max().item():.3f})")
        
        # Test mod√®le photo lourd
        print("üì¶ Chargement du mod√®le photo lourd...")
        checkpoint = torch.load('picture_training_enhanced/models/best_model.pth', map_location='cpu')
        
        from picture_training_enhanced.models.photo_config import create_photo_model
        photo_model = create_photo_model(
            num_classes=8,
            model_name='efficientnet-b1',
            pretrained=False
        )
        photo_model.load_state_dict(checkpoint['model_state_dict'])
        photo_model.eval()
        
        # Test avec image synth√©tique
        with torch.no_grad():
            photo_input = torch.randn(1, 3, 224, 224)
            photo_output = photo_model(photo_input)
            photo_probs = torch.softmax(photo_output, dim=1)
            photo_pred = torch.argmax(photo_probs, dim=1)
            
        class_names_photo = ['bat', 'owl', 'raccoon', 'opossum', 'deer', 'fox', 'coyote', 'unknown']
        print(f"‚úÖ Photo heavy - Pr√©diction: {class_names_photo[photo_pred.item()]} (confiance: {photo_probs.max().item():.3f})")
        
        # Test mod√®les l√©gers
        print("üì¶ Test des mod√®les l√©gers...")
        
        # Audio l√©ger
        audio_light_checkpoint = torch.load('mobile_models/audio_light_model.pth', map_location='cpu')
        audio_light_model = create_audio_model(
            num_classes=6,
            model_name='efficientnet-b0',
            pretrained=False
        )
        audio_light_model.load_state_dict(audio_light_checkpoint['model_state_dict'])
        audio_light_model.eval()
        
        with torch.no_grad():
            audio_light_output = audio_light_model(audio_input)
            audio_light_probs = torch.softmax(audio_light_output, dim=1)
            audio_light_pred = torch.argmax(audio_light_probs, dim=1)
        
        print(f"‚úÖ Audio light - Pr√©diction: {class_names_audio[audio_light_pred.item()]} (confiance: {audio_light_probs.max().item():.3f})")
        
        # Photo l√©ger
        photo_light_checkpoint = torch.load('mobile_models/photo_light_model.pth', map_location='cpu')
        photo_light_model = create_photo_model(
            num_classes=8,
            model_name='efficientnet-b0',
            pretrained=False
        )
        photo_light_model.load_state_dict(photo_light_checkpoint['model_state_dict'])
        photo_light_model.eval()
        
        with torch.no_grad():
            photo_light_output = photo_light_model(photo_input)
            photo_light_probs = torch.softmax(photo_light_output, dim=1)
            photo_light_pred = torch.argmax(photo_light_probs, dim=1)
        
        print(f"‚úÖ Photo light - Pr√©diction: {class_names_photo[photo_light_pred.item()]} (confiance: {photo_light_probs.max().item():.3f})")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur test inf√©rence: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_unified_router():
    """Test le routeur unifi√©."""
    print("\\nüéØ Test du routeur de pr√©dictions")
    print("=" * 50)
    
    try:
        from unified_prediction_system.prediction_router import get_prediction_router
        router = get_prediction_router()
        
        print(f"‚úÖ Routeur initialis√© avec {len(router.model_pool.heavy_models)} mod√®les lourds")
        
        # Test route recommandation
        audio_model = router.get_recommended_model('audio', 'vps')
        if audio_model:
            print(f"‚úÖ Mod√®le audio recommand√© pour VPS: {audio_model.model_id}")
        
        photo_model = router.get_recommended_model('photo', 'ios')
        if photo_model:
            print(f"‚úÖ Mod√®le photo recommand√© pour iOS: {photo_model.model_id}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur test routeur: {e}")
        return False

def generate_test_report():
    """G√©n√®re un rapport de test."""
    print("\\nüìÑ G√©n√©ration du rapport de test")
    print("=" * 50)
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'test_results': {
            'model_registry': test_model_loading(),
            'model_inference': test_model_inference(),
            'unified_router': test_unified_router()
        },
        'architecture_summary': {
            'models_created': 4,
            'heavy_models': {
                'audio': 'audio_training_efficientnet/models/best_model.pth (25.3MB)',
                'photo': 'picture_training_enhanced/models/best_model.pth (25.3MB)'
            },
            'light_models': {
                'audio': 'mobile_models/audio_light_model.pth (15.6MB)',
                'photo': 'mobile_models/photo_light_model.pth (15.6MB)'
            },
            'total_size_mb': 110.7,
            'compression_ratio': '38.3%'
        }
    }
    
    # Sauvegarder le rapport
    report_path = Path('unified_system_test_report.json')
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"‚úÖ Rapport sauvegard√©: {report_path}")
    
    # R√©sum√©
    successes = sum(1 for v in report['test_results'].values() if v)
    total_tests = len(report['test_results'])
    
    print(f"\\nüéâ R√âSUM√â DES TESTS: {successes}/{total_tests} r√©ussis")
    
    if successes == total_tests:
        print("‚úÖ Architecture edge-to-cloud op√©rationnelle!")
    else:
        print("‚ö†Ô∏è Certains tests ont √©chou√©")
    
    return report

def main():
    """Fonction principale de test."""
    print("üåô NightScan - Test du Syst√®me Unifi√© EfficientNet")
    print("=" * 60)
    
    report = generate_test_report()
    
    return 0 if all(report['test_results'].values()) else 1

if __name__ == "__main__":
    sys.exit(main())