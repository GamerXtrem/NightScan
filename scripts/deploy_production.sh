#!/bin/bash
# Script d√©ploiement production NightScan avec Blue-Green deployment
set -e

echo "üöÄ D√âPLOIEMENT PRODUCTION NIGHTSCAN"
echo "==================================="

# Configuration
PRODUCTION_HOST="${PRODUCTION_SERVER:-production.nightscan.com}"
PRODUCTION_USER="${PRODUCTION_USER:-deploy}"
DEPLOYMENT_DIR="/opt/nightscan"
BLUE_DIR="$DEPLOYMENT_DIR/blue"
GREEN_DIR="$DEPLOYMENT_DIR/green"
CURRENT_LINK="$DEPLOYMENT_DIR/current"

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m'

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_blue() {
    echo -e "${BLUE}[BLUE]${NC} $1"
}

# V√©rification pr√©requis production
check_production_prerequisites() {
    log_info "V√©rification pr√©requis production..."
    
    if [[ -z "$PRODUCTION_SSH_KEY" ]]; then
        log_error "PRODUCTION_SSH_KEY non d√©fini"
        exit 1
    fi
    
    if [[ -z "$DATABASE_URL" ]]; then
        log_error "DATABASE_URL non d√©fini"
        exit 1
    fi
    
    if [[ -z "$GITHUB_SHA" ]]; then
        log_error "GITHUB_SHA non d√©fini"
        exit 1
    fi
    
    # V√©rifier que c'est bien main branch
    if [[ "$GITHUB_REF" != "refs/heads/main" ]]; then
        log_error "D√©ploiement production autoris√© seulement depuis main"
        exit 1
    fi
    
    # Tests pr√©-d√©ploiement pass√©s
    if [[ ! -f "pre_deployment_check.passed" ]]; then
        log_error "Tests pr√©-d√©ploiement non pass√©s"
        exit 1
    fi
    
    log_info "‚úÖ Pr√©requis production valid√©s"
}

# Configuration SSH s√©curis√©e
setup_production_ssh() {
    log_info "Configuration SSH production..."
    
    mkdir -p ~/.ssh
    echo "$PRODUCTION_SSH_KEY" > ~/.ssh/production_key
    chmod 600 ~/.ssh/production_key
    
    # Configuration SSH stricte pour production
    cat > ~/.ssh/config << EOF
Host production
    HostName $PRODUCTION_HOST
    User $PRODUCTION_USER
    IdentityFile ~/.ssh/production_key
    StrictHostKeyChecking yes
    UserKnownHostsFile ~/.ssh/known_hosts_production
    ServerAliveInterval 60
    ServerAliveCountMax 3
EOF
    
    # Host key verification
    ssh-keyscan -H "$PRODUCTION_HOST" > ~/.ssh/known_hosts_production
    
    log_info "‚úÖ SSH production configur√©"
}

# D√©terminer environnement actuel (blue/green)
detect_current_environment() {
    log_info "D√©tection environnement actuel..."
    
    CURRENT_ENV=$(ssh production << 'EOF'
        if [[ -L "$CURRENT_LINK" ]]; then
            CURRENT_TARGET=$(readlink "$CURRENT_LINK")
            if [[ "$CURRENT_TARGET" == *"blue"* ]]; then
                echo "blue"
            elif [[ "$CURRENT_TARGET" == *"green"* ]]; then
                echo "green"
            else
                echo "unknown"
            fi
        else
            echo "none"
        fi
EOF
    )
    
    if [[ "$CURRENT_ENV" == "blue" ]]; then
        DEPLOY_ENV="green"
        STANDBY_ENV="blue"
    else
        DEPLOY_ENV="blue"
        STANDBY_ENV="green"
    fi
    
    log_info "Environnement actuel: $CURRENT_ENV"
    log_info "D√©ploiement vers: $DEPLOY_ENV"
    
    export CURRENT_ENV DEPLOY_ENV STANDBY_ENV
}

# Backup production critique
backup_production() {
    log_info "Backup production critique..."
    
    ssh production << EOF
        set -e
        
        BACKUP_TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
        BACKUP_PATH="/opt/nightscan/backups/production_\$BACKUP_TIMESTAMP"
        mkdir -p "\$BACKUP_PATH"
        
        # Backup base donn√©es avec compression
        pg_dump "$DATABASE_URL" | gzip > "\$BACKUP_PATH/database.sql.gz"
        
        # Backup Redis
        redis-cli --rdb "\$BACKUP_PATH/redis.rdb"
        
        # Backup configuration
        cp -r "$DEPLOYMENT_DIR/config" "\$BACKUP_PATH/"
        
        # Backup uploads/models
        tar -czf "\$BACKUP_PATH/user_data.tar.gz" \
            "$DEPLOYMENT_DIR/uploads" \
            "$DEPLOYMENT_DIR/models" 2>/dev/null || true
        
        # Upload vers S3 si configur√©
        if command -v aws &> /dev/null && [[ -n "\$AWS_BACKUP_BUCKET" ]]; then
            aws s3 sync "\$BACKUP_PATH" "s3://\$AWS_BACKUP_BUCKET/nightscan/\$BACKUP_TIMESTAMP/"
        fi
        
        echo "‚úÖ Backup cr√©√©: \$BACKUP_PATH"
        echo "\$BACKUP_PATH" > /tmp/latest_backup_path
EOF
    
    log_info "‚úÖ Backup production termin√©"
}

# D√©ploiement Blue-Green
deploy_to_environment() {
    log_info "D√©ploiement vers environnement $DEPLOY_ENV..."
    
    # Pr√©paration archive optimis√©e
    tar -czf nightscan-production.tar.gz \
        --exclude='.git' \
        --exclude='node_modules' \
        --exclude='__pycache__' \
        --exclude='.pytest_cache' \
        --exclude='htmlcov' \
        --exclude='logs/*' \
        --exclude='*.pyc' \
        .
    
    # Upload s√©curis√©
    scp nightscan-production.tar.gz production:/tmp/
    
    ssh production << EOF
        set -e
        
        DEPLOY_DIR="$DEPLOYMENT_DIR/$DEPLOY_ENV"
        
        # Nettoyage environnement cible
        rm -rf "\$DEPLOY_DIR"
        mkdir -p "\$DEPLOY_DIR"
        
        # Extraction
        cd "\$DEPLOY_DIR"
        tar -xzf /tmp/nightscan-production.tar.gz
        rm /tmp/nightscan-production.tar.gz
        
        # Installation d√©pendances dans environnement isol√©
        python3 -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install --no-cache-dir -r requirements.txt
        
        # Configuration production
        cp config/unified/production.json config/current.json
        
        # Permissions s√©curis√©es
        chown -R nightscan:nightscan "\$DEPLOY_DIR"
        chmod -R 750 "\$DEPLOY_DIR"
        chmod 640 "\$DEPLOY_DIR/config/current.json"
        
        echo "‚úÖ D√©ploiement $DEPLOY_ENV termin√©"
EOF
    
    log_info "‚úÖ D√©ploiement vers $DEPLOY_ENV termin√©"
}

# Tests environnement d√©ploy√©
test_deployed_environment() {
    log_info "Tests environnement $DEPLOY_ENV..."
    
    ssh production << EOF
        set -e
        
        cd "$DEPLOYMENT_DIR/$DEPLOY_ENV"
        source venv/bin/activate
        
        # Variables environnement production
        export NIGHTSCAN_ENV=production
        export NIGHTSCAN_CONFIG_FILE="$DEPLOYMENT_DIR/$DEPLOY_ENV/config/current.json"
        export DATABASE_URL="$DATABASE_URL"
        
        # Tests rapides
        python -c "import web.app; print('‚úÖ Import web.app OK')"
        python -c "import api_v1; print('‚úÖ Import api_v1 OK')"
        python -c "import unified_config; print('‚úÖ Import unified_config OK')"
        
        # Test connexions critiques
        python -c "
import psycopg2
import redis
import os

# Test PostgreSQL
conn = psycopg2.connect(os.environ['DATABASE_URL'])
cursor = conn.cursor()
cursor.execute('SELECT 1')
print('‚úÖ PostgreSQL connexion OK')
cursor.close()
conn.close()

# Test Redis
r = redis.from_url(os.environ.get('REDIS_URL', 'redis://localhost:6379'))
r.ping()
print('‚úÖ Redis connexion OK')
"
        
        echo "‚úÖ Tests environnement $DEPLOY_ENV r√©ussis"
EOF
    
    log_info "‚úÖ Tests environnement $DEPLOY_ENV r√©ussis"
}

# D√©marrage services dans nouvel environnement
start_services_in_environment() {
    log_info "D√©marrage services dans $DEPLOY_ENV..."
    
    ssh production << EOF
        set -e
        
        cd "$DEPLOYMENT_DIR/$DEPLOY_ENV"
        
        # Ports pour nouvel environnement
        if [[ "$DEPLOY_ENV" == "blue" ]]; then
            WEB_PORT=8010
            API_PORT=8011
            PREDICTION_PORT=8012
        else
            WEB_PORT=8020
            API_PORT=8021
            PREDICTION_PORT=8022
        fi
        
        # D√©marrage avec docker-compose sp√©cifique
        if [[ -f "docker-compose.production-$DEPLOY_ENV.yml" ]]; then
            docker-compose -f "docker-compose.production-$DEPLOY_ENV.yml" up -d
        else
            # D√©marrage manuel avec ports d√©di√©s
            source venv/bin/activate
            export NIGHTSCAN_ENV=production
            export NIGHTSCAN_CONFIG_FILE="$DEPLOYMENT_DIR/$DEPLOY_ENV/config/current.json"
            
            # Web application
            nohup gunicorn -w 4 -b "0.0.0.0:\$WEB_PORT" web.app:application \
                --access-logfile logs/web-access.log \
                --error-logfile logs/web-error.log \
                --pid logs/web.pid \
                --daemon
            
            # API v1
            nohup gunicorn -w 4 -b "0.0.0.0:\$API_PORT" api_v1:app \
                --access-logfile logs/api-access.log \
                --error-logfile logs/api-error.log \
                --pid logs/api.pid \
                --daemon
            
            # Prediction API
            nohup python unified_prediction_system/unified_prediction_api.py \
                --port=\$PREDICTION_PORT \
                > logs/prediction.log 2>&1 &
            echo \$! > logs/prediction.pid
            
            # Celery worker (partag√© entre environnements)
            if ! pgrep -f "celery.*worker" > /dev/null; then
                nohup celery -A web.tasks worker --loglevel=info \
                    > logs/celery.log 2>&1 &
                echo \$! > logs/celery.pid
            fi
        fi
        
        echo "‚úÖ Services $DEPLOY_ENV d√©marr√©s"
        echo "Web: \$WEB_PORT, API: \$API_PORT, Prediction: \$PREDICTION_PORT"
EOF
    
    log_info "‚úÖ Services $DEPLOY_ENV d√©marr√©s"
}

# Tests sant√© nouvel environnement
health_check_new_environment() {
    log_info "Tests sant√© nouvel environnement..."
    
    # R√©cup√©rer ports depuis serveur
    PORTS=$(ssh production << EOF
        if [[ "$DEPLOY_ENV" == "blue" ]]; then
            echo "8010 8011 8012"
        else
            echo "8020 8021 8022"
        fi
EOF
    )
    
    WEB_PORT=$(echo $PORTS | cut -d' ' -f1)
    API_PORT=$(echo $PORTS | cut -d' ' -f2)
    PREDICTION_PORT=$(echo $PORTS | cut -d' ' -f3)
    
    # Attendre d√©marrage
    sleep 45
    
    # Tests sant√© via SSH tunnel (plus s√©curis√©)
    ssh -L "9080:localhost:$WEB_PORT" \
        -L "9081:localhost:$API_PORT" \
        -L "9082:localhost:$PREDICTION_PORT" \
        production sleep 60 &
    SSH_PID=$!
    
    sleep 10
    
    # Tests endpoints
    if curl -f "http://localhost:9080/health" > /dev/null 2>&1; then
        log_info "‚úÖ Web app $DEPLOY_ENV OK"
    else
        log_error "‚ùå Web app $DEPLOY_ENV √©chec"
        kill $SSH_PID
        return 1
    fi
    
    if curl -f "http://localhost:9081/api/v1/health" > /dev/null 2>&1; then
        log_info "‚úÖ API $DEPLOY_ENV OK"
    else
        log_error "‚ùå API $DEPLOY_ENV √©chec"
        kill $SSH_PID
        return 1
    fi
    
    if curl -f "http://localhost:9082/health" > /dev/null 2>&1; then
        log_info "‚úÖ Prediction API $DEPLOY_ENV OK"
    else
        log_warn "‚ö†Ô∏è Prediction API $DEPLOY_ENV non accessible"
    fi
    
    kill $SSH_PID
    
    log_info "‚úÖ Tests sant√© $DEPLOY_ENV r√©ussis"
}

# Basculement traffic (Blue-Green switch)
switch_traffic() {
    log_info "Basculement traffic vers $DEPLOY_ENV..."
    
    ssh production << EOF
        set -e
        
        # Mise √† jour load balancer/nginx
        if [[ "$DEPLOY_ENV" == "blue" ]]; then
            UPSTREAM_PORTS="8010 8011"
        else
            UPSTREAM_PORTS="8020 8021"
        fi
        
        # Mise √† jour configuration nginx
        cat > /etc/nginx/sites-available/nightscan << 'NGINX_CONF'
upstream nightscan_web {
    server localhost:$(echo $UPSTREAM_PORTS | cut -d' ' -f1);
}

upstream nightscan_api {
    server localhost:$(echo $UPSTREAM_PORTS | cut -d' ' -f2);
}

server {
    listen 80;
    listen 443 ssl http2;
    server_name production.nightscan.com;
    
    # SSL configuration
    ssl_certificate /etc/ssl/certs/nightscan.pem;
    ssl_certificate_key /etc/ssl/private/nightscan.key;
    
    location / {
        proxy_pass http://nightscan_web;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
    }
    
    location /api/ {
        proxy_pass http://nightscan_api;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
    }
}
NGINX_CONF
        
        # Test configuration nginx
        nginx -t
        
        # Rechargement graceful nginx
        nginx -s reload
        
        # Mise √† jour symlink current
        ln -sfn "$DEPLOYMENT_DIR/$DEPLOY_ENV" "$CURRENT_LINK"
        
        echo "‚úÖ Traffic bascul√© vers $DEPLOY_ENV"
EOF
    
    log_info "‚úÖ Traffic bascul√© vers $DEPLOY_ENV"
}

# Tests post-basculement
post_switch_tests() {
    log_info "Tests post-basculement..."
    
    sleep 30
    
    # Tests depuis l'ext√©rieur
    PRODUCTION_URL="https://$PRODUCTION_HOST"
    
    if curl -f "$PRODUCTION_URL/health" > /dev/null 2>&1; then
        log_info "‚úÖ Production web accessible"
    else
        log_error "‚ùå Production web non accessible"
        return 1
    fi
    
    if curl -f "$PRODUCTION_URL/api/v1/health" > /dev/null 2>&1; then
        log_info "‚úÖ Production API accessible"
    else
        log_error "‚ùå Production API non accessible"
        return 1
    fi
    
    # Tests fonctionnels
    python scripts/production_smoke_tests.py
    
    log_info "‚úÖ Tests post-basculement r√©ussis"
}

# Arr√™t ancien environnement
stop_old_environment() {
    log_info "Arr√™t ancien environnement $STANDBY_ENV..."
    
    ssh production << EOF
        set -e
        
        cd "$DEPLOYMENT_DIR/$STANDBY_ENV"
        
        # Arr√™t services
        if [[ -f "docker-compose.production-$STANDBY_ENV.yml" ]]; then
            docker-compose -f "docker-compose.production-$STANDBY_ENV.yml" down
        else
            # Arr√™t manuel via PID files
            for pid_file in logs/*.pid; do
                if [[ -f "\$pid_file" ]]; then
                    kill \$(cat "\$pid_file") 2>/dev/null || true
                    rm "\$pid_file"
                fi
            done
        fi
        
        echo "‚úÖ Ancien environnement $STANDBY_ENV arr√™t√©"
EOF
    
    log_info "‚úÖ Ancien environnement $STANDBY_ENV arr√™t√©"
}

# Rollback en cas d'√©chec
emergency_rollback() {
    log_error "√âCHEC D√âPLOIEMENT - ROLLBACK D'URGENCE!"
    
    ssh production << EOF
        set -e
        
        # Restaurer ancien environnement
        if [[ "$CURRENT_ENV" != "none" ]]; then
            ln -sfn "$DEPLOYMENT_DIR/$CURRENT_ENV" "$CURRENT_LINK"
            
            # Red√©marrer services si n√©cessaire
            cd "$DEPLOYMENT_DIR/$CURRENT_ENV"
            
            # V√©rifier si services tournent
            if ! curl -f "http://localhost:8000/health" > /dev/null 2>&1; then
                # Red√©marrage services
                if [[ -f "docker-compose.production-$CURRENT_ENV.yml" ]]; then
                    docker-compose -f "docker-compose.production-$CURRENT_ENV.yml" up -d
                fi
            fi
            
            # Recharger nginx
            nginx -s reload
            
            echo "‚úÖ Rollback vers $CURRENT_ENV termin√©"
        fi
        
        # Arr√™ter environnement d√©faillant
        cd "$DEPLOYMENT_DIR/$DEPLOY_ENV"
        if [[ -f "docker-compose.production-$DEPLOY_ENV.yml" ]]; then
            docker-compose -f "docker-compose.production-$DEPLOY_ENV.yml" down
        fi
EOF
    
    log_error "Rollback termin√© - Production restaur√©e"
    exit 1
}

# Nettoyage post-d√©ploiement
cleanup_deployment() {
    log_info "Nettoyage post-d√©ploiement..."
    
    ssh production << EOF
        set -e
        
        # Nettoyage anciens backups (>30 jours)
        find "/opt/nightscan/backups" -name "production_*" -mtime +30 -exec rm -rf {} \;
        
        # Nettoyage logs anciens
        find "/opt/nightscan/*/logs" -name "*.log" -mtime +7 -exec gzip {} \;
        find "/opt/nightscan/*/logs" -name "*.log.gz" -mtime +30 -delete
        
        # Nettoyage Docker si utilis√©
        docker system prune -f
        
        echo "‚úÖ Nettoyage termin√©"
EOF
    
    log_info "‚úÖ Nettoyage termin√©"
}

# Fonction principale
main() {
    # Trap pour rollback automatique
    trap emergency_rollback ERR
    
    check_production_prerequisites
    setup_production_ssh
    detect_current_environment
    backup_production
    deploy_to_environment
    test_deployed_environment
    start_services_in_environment
    health_check_new_environment
    switch_traffic
    post_switch_tests
    stop_old_environment
    cleanup_deployment
    
    log_info "üéâ D√âPLOIEMENT PRODUCTION R√âUSSI!"
    echo "===================================="
    echo "Environment: $DEPLOY_ENV"
    echo "SHA: $GITHUB_SHA"
    echo "Timestamp: $(date)"
    echo "Production URL: https://$PRODUCTION_HOST"
}

# Ex√©cution
main "$@"