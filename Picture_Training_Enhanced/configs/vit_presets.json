{
  "vit_b_16_balanced": {
    "model_name": "vit_b_16",
    "architecture": "vit",
    "num_classes": 8,
    "pretrained": true,
    "dropout_rate": 0.1,
    "input_size": [224, 224],
    "num_channels": 3,
    "learning_rate": 0.00001,
    "weight_decay": 0.0001,
    "batch_size": 16,
    "epochs": 120,
    "patience": 20,
    "optimizer": "adamw",
    "scheduler": "cosine",
    "mixed_precision": true,
    "gradient_clipping": 1.0,
    "use_augmentation": true,
    "rotation_degrees": 10,
    "color_jitter_strength": 0.2,
    "horizontal_flip_prob": 0.5,
    "vertical_flip_prob": 0.1,
    "cutmix_prob": 0.3,
    "mixup_alpha": 0.2,
    "use_class_weights": true,
    "device": "auto",
    "freeze_backbone": true,
    "unfreeze_at_epoch": 20,
    "description": "Balanced preset for Vision Transformer B/16. Good for medium-sized datasets with fine-tuning."
  },
  
  "vit_b_16_quality": {
    "model_name": "vit_b_16",
    "architecture": "vit",
    "num_classes": 8,
    "pretrained": true,
    "dropout_rate": 0.2,
    "input_size": [224, 224],
    "num_channels": 3,
    "learning_rate": 0.000005,
    "weight_decay": 0.0001,
    "batch_size": 12,
    "epochs": 150,
    "patience": 25,
    "optimizer": "adamw",
    "scheduler": "cosine",
    "mixed_precision": true,
    "gradient_clipping": 1.0,
    "use_augmentation": true,
    "rotation_degrees": 15,
    "color_jitter_strength": 0.3,
    "horizontal_flip_prob": 0.5,
    "vertical_flip_prob": 0.2,
    "cutmix_prob": 0.4,
    "mixup_alpha": 0.3,
    "use_class_weights": true,
    "device": "auto",
    "freeze_backbone": true,
    "unfreeze_at_epoch": 30,
    "description": "High-quality preset for Vision Transformer B/16. Optimized for best performance on large datasets."
  },
  
  "vit_b_32_fast": {
    "model_name": "vit_b_32",
    "architecture": "vit",
    "num_classes": 8,
    "pretrained": true,
    "dropout_rate": 0.1,
    "input_size": [224, 224],
    "num_channels": 3,
    "learning_rate": 0.00005,
    "weight_decay": 0.0001,
    "batch_size": 32,
    "epochs": 80,
    "patience": 15,
    "optimizer": "adamw",
    "scheduler": "cosine",
    "mixed_precision": true,
    "gradient_clipping": 1.0,
    "use_augmentation": true,
    "rotation_degrees": 10,
    "color_jitter_strength": 0.2,
    "horizontal_flip_prob": 0.5,
    "vertical_flip_prob": 0.1,
    "cutmix_prob": 0.3,
    "mixup_alpha": 0.1,
    "use_class_weights": true,
    "device": "auto",
    "freeze_backbone": true,
    "unfreeze_at_epoch": 15,
    "description": "Fast training preset for Vision Transformer B/32. Faster training with larger patch size."
  },
  
  "vit_b_16_finetune": {
    "model_name": "vit_b_16",
    "architecture": "vit",
    "num_classes": 8,
    "pretrained": true,
    "dropout_rate": 0.1,
    "input_size": [224, 224],
    "num_channels": 3,
    "learning_rate": 0.000001,
    "weight_decay": 0.0001,
    "batch_size": 24,
    "epochs": 100,
    "patience": 20,
    "optimizer": "adamw",
    "scheduler": "cosine",
    "mixed_precision": true,
    "gradient_clipping": 1.0,
    "use_augmentation": true,
    "rotation_degrees": 5,
    "color_jitter_strength": 0.1,
    "horizontal_flip_prob": 0.5,
    "vertical_flip_prob": 0.1,
    "cutmix_prob": 0.2,
    "mixup_alpha": 0.1,
    "use_class_weights": true,
    "device": "auto",
    "freeze_backbone": true,
    "unfreeze_at_epoch": 40,
    "description": "Conservative fine-tuning preset for Vision Transformer B/16. Minimal changes to pretrained weights."
  }
}